{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "great-official",
   "metadata": {},
   "source": [
    "# Highly Imbalanced Dataset Problem\n",
    "## 정의와 특성\n",
    "데이터 클래스 비율의 차이가 클 경우 학습시 모형에서 일어나는 문제\n",
    "- 클래스 비율이 많은 예측력은 높아 모형의 정확도(Accuracy)가 높지만 데이터 수가 적은 클레스의 Recall이 작아지는 현상.\n",
    "- 데이터셋 예시: 카드 부정사용 기록, 질병 데이터\n",
    "\n",
    "\n",
    "## 해결방법\n",
    "\n",
    "![title](undersampling_oversampling.png)\n",
    "- 언더샘플링(Under Sampling): 다수 클래스 데이터에서 일부만 사용\n",
    "- 오버샘플링(Over Sampling): 소수 클래스 데이터를 증가\n",
    "- 복합샘플링(Combining Over and Under Sampling): Over Sampling + Under Sampling\n",
    "\n",
    "## Under Sampling\n",
    "- 장점: 계산 시간 감소\n",
    "- 단점: 정보 손실 \n",
    "\n",
    "### Random Under Sampling\n",
    "무작위로 데이터를 제거하여 클래스별로 같은 수를 가지도록 한다.  \n",
    "수행시마다 다른 샘플링이 이뤄진다.\n",
    "\n",
    "### Tomek Links\n",
    "서로 다른 클레스에 속하는 한 쌍의 데이터 중에 다수의 클래스가 있는 데이터를 제거하는 방식.  \n",
    "![](tomek_links.png)\n",
    "\n",
    "\n",
    "## Over Sampling\n",
    "- 장점: 정보 손실 없음\n",
    "- 단점: 과적합 문제(Precision 감소 가능성), 이상치에 민감.\n",
    "\n",
    "### Random Over Samping\n",
    "소수 클래스의 데이터를 복제. 가중치를 증가 방식과 유사.\n",
    "\n",
    "### SMOTE\n",
    "Synthetic Minority Oversampling TEchnique.  \n",
    "낮은 비율 클래스 데이터들의 최근접 이웃을 이용하여 새 데이터를 생성.\n",
    "![](SMOTH.png)\n",
    "\n",
    "\n",
    "## Combining Over and Under Sampling\n",
    "### SMOTETomek\n",
    "SMOTE + Tomek links\n",
    "\n",
    "\n",
    "reference.  \n",
    "https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets  \n",
    "https://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enormous-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge imbalanced-learn -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-modern",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-valentine",
   "metadata": {},
   "source": [
    "Framingham Heart study dataset\n",
    "\n",
    "#### Content\n",
    "\n",
    "Dependent variable\n",
    "- diabetes: 0 = No; 1 = Yes\n",
    "\n",
    "\n",
    "Independent variables\n",
    "- male: 0 = Female; 1 = Male\n",
    "- age: Age at exam time.\n",
    "- education: 1 = Some High School; 2 = High School or GED; 3 = Some College or Vocational School; 4 = college\n",
    "- currentSmoker: 0 = nonsmoker; 1 = smoker\n",
    "- cigsPerDay: number of cigarettes smoked per day (estimated average)\n",
    "- BPMeds: 0 = Not on Blood Pressure medications; 1 = Is on Blood Pressure medications\n",
    "- prevalentStroke: prevalentHyp\n",
    "- totChol: mg/dL\n",
    "- sysBP: mmHg\n",
    "- diaBP: mmHg\n",
    "- BMI: Body Mass Index calculated as: Weight (kg) / Height(meter-squared)\n",
    "- heartRate: Beats/Min (Ventricular)\n",
    "- glucose: mg/dL\n",
    "- TenYearCHD\n",
    "\n",
    "reference.\n",
    "https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-modem",
   "metadata": {},
   "source": [
    "### Step1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monthly-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'framingham.csv' 파일 읽기 pd.read_csv()\n",
    "# df shape 확인 \n",
    "\n",
    "df = pd.read_csv('framingham.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "divine-church",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df head 행 보기\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chemical-junior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4240 entries, 0 to 4239\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             4240 non-null   int64  \n",
      " 1   age              4240 non-null   int64  \n",
      " 2   education        4135 non-null   float64\n",
      " 3   currentSmoker    4240 non-null   int64  \n",
      " 4   cigsPerDay       4211 non-null   float64\n",
      " 5   BPMeds           4187 non-null   float64\n",
      " 6   prevalentStroke  4240 non-null   int64  \n",
      " 7   prevalentHyp     4240 non-null   int64  \n",
      " 8   diabetes         4240 non-null   int64  \n",
      " 9   totChol          4190 non-null   float64\n",
      " 10  sysBP            4240 non-null   float64\n",
      " 11  diaBP            4240 non-null   float64\n",
      " 12  BMI              4221 non-null   float64\n",
      " 13  heartRate        4239 non-null   float64\n",
      " 14  glucose          3852 non-null   float64\n",
      " 15  TenYearCHD       4240 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 530.1 KB\n"
     ]
    }
   ],
   "source": [
    "# df info 보기\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decreased-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4135.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4211.000000</td>\n",
       "      <td>4187.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4221.000000</td>\n",
       "      <td>4239.000000</td>\n",
       "      <td>3852.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429245</td>\n",
       "      <td>49.580189</td>\n",
       "      <td>1.979444</td>\n",
       "      <td>0.494104</td>\n",
       "      <td>9.005937</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.310613</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>236.699523</td>\n",
       "      <td>132.354599</td>\n",
       "      <td>82.897759</td>\n",
       "      <td>25.800801</td>\n",
       "      <td>75.878981</td>\n",
       "      <td>81.963655</td>\n",
       "      <td>0.151887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495027</td>\n",
       "      <td>8.572942</td>\n",
       "      <td>1.019791</td>\n",
       "      <td>0.500024</td>\n",
       "      <td>11.922462</td>\n",
       "      <td>0.169544</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.158280</td>\n",
       "      <td>44.591284</td>\n",
       "      <td>22.033300</td>\n",
       "      <td>11.910394</td>\n",
       "      <td>4.079840</td>\n",
       "      <td>12.025348</td>\n",
       "      <td>23.954335</td>\n",
       "      <td>0.358953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>56.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              male          age    education  currentSmoker   cigsPerDay  \\\n",
       "count  4240.000000  4240.000000  4135.000000    4240.000000  4211.000000   \n",
       "mean      0.429245    49.580189     1.979444       0.494104     9.005937   \n",
       "std       0.495027     8.572942     1.019791       0.500024    11.922462   \n",
       "min       0.000000    32.000000     1.000000       0.000000     0.000000   \n",
       "25%       0.000000    42.000000     1.000000       0.000000     0.000000   \n",
       "50%       0.000000    49.000000     2.000000       0.000000     0.000000   \n",
       "75%       1.000000    56.000000     3.000000       1.000000    20.000000   \n",
       "max       1.000000    70.000000     4.000000       1.000000    70.000000   \n",
       "\n",
       "            BPMeds  prevalentStroke  prevalentHyp     diabetes      totChol  \\\n",
       "count  4187.000000      4240.000000   4240.000000  4240.000000  4190.000000   \n",
       "mean      0.029615         0.005896      0.310613     0.025708   236.699523   \n",
       "std       0.169544         0.076569      0.462799     0.158280    44.591284   \n",
       "min       0.000000         0.000000      0.000000     0.000000   107.000000   \n",
       "25%       0.000000         0.000000      0.000000     0.000000   206.000000   \n",
       "50%       0.000000         0.000000      0.000000     0.000000   234.000000   \n",
       "75%       0.000000         0.000000      1.000000     0.000000   263.000000   \n",
       "max       1.000000         1.000000      1.000000     1.000000   696.000000   \n",
       "\n",
       "             sysBP        diaBP          BMI    heartRate      glucose  \\\n",
       "count  4240.000000  4240.000000  4221.000000  4239.000000  3852.000000   \n",
       "mean    132.354599    82.897759    25.800801    75.878981    81.963655   \n",
       "std      22.033300    11.910394     4.079840    12.025348    23.954335   \n",
       "min      83.500000    48.000000    15.540000    44.000000    40.000000   \n",
       "25%     117.000000    75.000000    23.070000    68.000000    71.000000   \n",
       "50%     128.000000    82.000000    25.400000    75.000000    78.000000   \n",
       "75%     144.000000    90.000000    28.040000    83.000000    87.000000   \n",
       "max     295.000000   142.500000    56.800000   143.000000   394.000000   \n",
       "\n",
       "        TenYearCHD  \n",
       "count  4240.000000  \n",
       "mean      0.151887  \n",
       "std       0.358953  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df descriptive statistics\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "innovative-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3658, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop null data dropna(how='any', axis=0)\n",
    "\n",
    "df = df.dropna(how='any', axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-butler",
   "metadata": {},
   "source": [
    "### Step2: Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "linear-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram\n",
    "\n",
    "df['diabetes'].hist(bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proper-forum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3559\n",
       "1      99\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value counts()\n",
    "\n",
    "df.diabetes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-glucose",
   "metadata": {},
   "source": [
    "### Step3: Define Train set and Test Set(Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "freelance-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 diabetes를 제외한 column까지 할당. axis=1 기준.\n",
    "# y에 diabetes column을 할당\n",
    "\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df.loc[:, 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personalized-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-upper",
   "metadata": {},
   "source": [
    "### Step4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respiratory-inspector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier에 RandomForestClassifier 할당\n",
    "# param: n_estimators = 10, criterion = 'entropy'\n",
    "# n_estimator: The number of trees in the forest.\n",
    "# criterion: gini or entropy\n",
    "# X_train, y_train으로 classifier에 fit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "increasing-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965823650034177"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "monetary-smell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795081967213115"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thick-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       709\n",
      "           1       1.00      0.35      0.52        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.99      0.67      0.75       732\n",
      "weighted avg       0.98      0.98      0.97       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict_test = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "\n",
    "model_results = dict()\n",
    "model_results['original'] = classification_report(y_test, y_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-exclusive",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-default",
   "metadata": {},
   "source": [
    "### Step3: Define Train set and Test Set(UnderSampling: Random Under Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "standard-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 diabetes를 제외한 column까지 할당. axis=1 기준.\n",
    "# y에 diabetes column을 할당\n",
    "\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df.loc[:, 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "russian-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "corrected-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    2850\n",
      "1      76\n",
      "Name: diabetes, dtype: int64\n",
      "After\n",
      "0    76\n",
      "1    76\n",
      "Name: diabetes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# sampler를 RandomUnderSampler 으로 할당.\n",
    "# fit_resample을 이용해서 sampling\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "print(\"Before\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "sampler = RandomUnderSampler()\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-harbor",
   "metadata": {},
   "source": [
    "### Step4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "broke-genre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier에 RandomForestClassifier 할당\n",
    "# param: n_estimators = 10, criterion = 'entropy'\n",
    "# n_estimator: The number of trees in the forest.\n",
    "# criterion: gini or entropy\n",
    "# X_train, y_train으로 classifier에 fit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adult-fight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "exclusive-magnitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647540983606558"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "instructional-guidance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93       709\n",
      "           1       0.18      0.91      0.30        23\n",
      "\n",
      "    accuracy                           0.86       732\n",
      "   macro avg       0.59      0.89      0.61       732\n",
      "weighted avg       0.97      0.86      0.91       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict_test = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "\n",
    "model_results['under_random'] = classification_report(y_test, y_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-member",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-recovery",
   "metadata": {},
   "source": [
    "### Step3: Define Train set and Test Set(UnderSampling: Tomek Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "designed-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 diabetes를 제외한 column까지 할당. axis=1 기준.\n",
    "# y에 diabetes column을 할당\n",
    "\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df.loc[:, 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "entitled-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "genuine-numbers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    2850\n",
      "1      76\n",
      "Name: diabetes, dtype: int64\n",
      "After\n",
      "0    2832\n",
      "1      76\n",
      "Name: diabetes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.under_sampling import TomekLinks\n",
    "# sampler를 TomekLinks 으로 할당.\n",
    "# fit_resample을 이용해서 sampling\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "print(\"Before\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "sampler = TomekLinks()\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-protein",
   "metadata": {},
   "source": [
    "### Step4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stock-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier에 RandomForestClassifier 할당\n",
    "# param: n_estimators = 10, criterion = 'entropy'\n",
    "# n_estimator: The number of trees in the forest.\n",
    "# criterion: gini or entropy\n",
    "# X_train, y_train으로 classifier에 fit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "prime-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965612104539202"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "clinical-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904371584699454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "radio-delay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       709\n",
      "           1       1.00      0.70      0.82        23\n",
      "\n",
      "    accuracy                           0.99       732\n",
      "   macro avg       1.00      0.85      0.91       732\n",
      "weighted avg       0.99      0.99      0.99       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict_test = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "\n",
    "model_results['under_tomek'] = classification_report(y_test, y_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-single",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-preliminary",
   "metadata": {},
   "source": [
    "### Step3: Define Train set and Test Set(Over Sampling: Random Over Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "varying-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 diabetes를 제외한 column까지 할당. axis=1 기준.\n",
    "# y에 diabetes column을 할당\n",
    "\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df.loc[:, 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sitting-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "introductory-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    2850\n",
      "1      76\n",
      "Name: diabetes, dtype: int64\n",
      "After\n",
      "0    2850\n",
      "1    2850\n",
      "Name: diabetes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# sampler를 TomekLinks 으로 할당.\n",
    "# fit_resample을 이용해서 sampling\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "print(\"Before\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "sampler = RandomOverSampler()\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-regular",
   "metadata": {},
   "source": [
    "### Step4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "minute-coach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier에 RandomForestClassifier 할당\n",
    "# param: n_estimators = 10, criterion = 'entropy'\n",
    "# n_estimator: The number of trees in the forest.\n",
    "# criterion: gini or entropy\n",
    "# X_train, y_train으로 classifier에 fit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "local-apparatus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "loved-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98224043715847"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "catholic-preservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       709\n",
      "           1       1.00      0.43      0.61        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.99      0.72      0.80       732\n",
      "weighted avg       0.98      0.98      0.98       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict_test = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "\n",
    "model_results['over_random'] = classification_report(y_test, y_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-credits",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-evening",
   "metadata": {},
   "source": [
    "### Step3: Define Train set and Test Set(Over Sampling: SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "chronic-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 diabetes를 제외한 column까지 할당. axis=1 기준.\n",
    "# y에 diabetes column을 할당\n",
    "\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df.loc[:, 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eligible-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ready-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    2850\n",
      "1      76\n",
      "Name: diabetes, dtype: int64\n",
      "After\n",
      "0    2850\n",
      "1    2850\n",
      "Name: diabetes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# sampler를 SMOTE 으로 할당.\n",
    "# fit_resample을 이용해서 sampling\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Before\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "sampler = SMOTE()\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-probe",
   "metadata": {},
   "source": [
    "### Step4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interracial-learning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier에 RandomForestClassifier 할당\n",
    "# param: n_estimators = 10, criterion = 'entropy'\n",
    "# n_estimator: The number of trees in the forest.\n",
    "# criterion: gini or entropy\n",
    "# X_train, y_train으로 classifier에 fit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "realistic-charger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996491228070176"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "taken-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9781420765027322"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "mysterious-pepper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       709\n",
      "           1       0.65      0.65      0.65        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.82      0.82      0.82       732\n",
      "weighted avg       0.98      0.98      0.98       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict_test = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "\n",
    "model_results['over_SMOTE'] = classification_report(y_test, y_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-adolescent",
   "metadata": {},
   "source": [
    "### Step3: Define Train set and Test Set(Combining Over and Under Sampling: SMOTETomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "prescribed-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 diabetes를 제외한 column까지 할당. axis=1 기준.\n",
    "# y에 diabetes column을 할당\n",
    "\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df.loc[:, 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "stretch-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "killing-merchandise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    2850\n",
      "1      76\n",
      "Name: diabetes, dtype: int64\n",
      "After\n",
      "0    2847\n",
      "1    2847\n",
      "Name: diabetes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.combine import SMOTETomek\n",
    "# sampler를 SMOTETomek 으로 할당.\n",
    "# fit_resample을 이용해서 sampling\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "print(\"Before\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "sampler = SMOTETomek()\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-services",
   "metadata": {},
   "source": [
    "### Step4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "horizontal-arrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier에 RandomForestClassifier 할당\n",
    "# param: n_estimators = 10, criterion = 'entropy'\n",
    "# n_estimator: The number of trees in the forest.\n",
    "# criterion: gini or entropy\n",
    "# X_train, y_train으로 classifier에 fit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "chinese-suffering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996487530734106"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "incorrect-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808743169398907"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "revised-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       709\n",
      "           1       0.80      0.52      0.63        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.89      0.76      0.81       732\n",
      "weighted avg       0.98      0.98      0.98       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict_test = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "\n",
    "model_results['combine_SMOTEtomek'] = classification_report(y_test, y_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-lighting",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-discipline",
   "metadata": {},
   "source": [
    "### Model Results w.r.t sampling types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "threaded-buffalo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       709\n",
      "           1       1.00      0.35      0.52        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.99      0.67      0.75       732\n",
      "weighted avg       0.98      0.98      0.97       732\n",
      "\n",
      "-------------------------------------------------------\n",
      "under_random\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93       709\n",
      "           1       0.18      0.91      0.30        23\n",
      "\n",
      "    accuracy                           0.86       732\n",
      "   macro avg       0.59      0.89      0.61       732\n",
      "weighted avg       0.97      0.86      0.91       732\n",
      "\n",
      "-------------------------------------------------------\n",
      "under_tomek\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       709\n",
      "           1       1.00      0.70      0.82        23\n",
      "\n",
      "    accuracy                           0.99       732\n",
      "   macro avg       1.00      0.85      0.91       732\n",
      "weighted avg       0.99      0.99      0.99       732\n",
      "\n",
      "-------------------------------------------------------\n",
      "over_random\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       709\n",
      "           1       1.00      0.43      0.61        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.99      0.72      0.80       732\n",
      "weighted avg       0.98      0.98      0.98       732\n",
      "\n",
      "-------------------------------------------------------\n",
      "over_SMOTE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       709\n",
      "           1       0.65      0.65      0.65        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.82      0.82      0.82       732\n",
      "weighted avg       0.98      0.98      0.98       732\n",
      "\n",
      "-------------------------------------------------------\n",
      "combine_SMOTEtomek\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       709\n",
      "           1       0.80      0.52      0.63        23\n",
      "\n",
      "    accuracy                           0.98       732\n",
      "   macro avg       0.89      0.76      0.81       732\n",
      "weighted avg       0.98      0.98      0.98       732\n",
      "\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k, v in model_results.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-photograph",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
